"""
ç®¡é“è°ƒåº¦å™¨ - åè°ƒå„ä¸ªæ¨¡å—è¿è¡Œ (v2 - ä½¿ç”¨ContentAnalyzer)
"""

import logging
from datetime import datetime
from typing import Optional

from modules import Fetcher, Classifier, Generator
from modules.content_analyzer import ContentAnalyzer


class Pipeline:
    """
    ç®¡é“è°ƒåº¦å™¨ (v2)

    æµç¨‹:
    1. Fetcher - æŠ“å–æ¨æ–‡
    2. ContentAnalyzer - åˆ†æå†…å®¹ï¼ˆåˆå¹¶Filter+Evaluatorï¼Œä¸€æ¬¡LLMè°ƒç”¨ï¼‰
    3. Classifier - å†…å®¹åˆ†ç±»
    4. Generator - ç”ŸæˆMarkdown

    ç›¸æ¯”v1çš„ä¼˜åŠ¿:
    - 4æ­¥æµç¨‹æ›¿ä»£5æ­¥
    - å•æ¬¡LLMåˆ¤æ–­ç›¸å…³æ€§+ä»·å€¼ï¼ŒèŠ‚çœAPIæˆæœ¬
    - ä¸ä¾èµ–å…³é”®è¯åˆ—è¡¨ï¼Œä¸ä¼šé—æ¼å†…å®¹
    - è¿½è¸ªåšä¸»è´¨é‡è¯„åˆ†
    """

    def __init__(self):
        self.logger = self._setup_logger()
        self.fetcher = Fetcher()
        self.analyzer = ContentAnalyzer()
        self.classifier = Classifier()
        self.generator = Generator()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger("Pipeline")
        logger.setLevel(logging.INFO)

        # é¿å…é‡å¤æ·»åŠ handler
        if not logger.handlers:
            handler = logging.StreamHandler()
            handler.setLevel(logging.INFO)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def run(self, input_file: str = None) -> Optional[str]:
        """
        è¿è¡Œå®Œæ•´ç®¡é“

        Args:
            input_file: å¯é€‰ï¼Œç›´æ¥ä½¿ç”¨æŒ‡å®šçš„åŸå§‹æ•°æ®æ–‡ä»¶ï¼ˆè·³è¿‡æŠ“å–ï¼‰

        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ— è¾“å‡ºåˆ™è¿”å› None
        """
        start_time = datetime.now()
        self.logger.info("="*70)
        self.logger.info(f"ç®¡é“å¯åŠ¨ (v2): {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("="*70)

        try:
            # 1. æŠ“å–ï¼ˆæˆ–ä½¿ç”¨æŒ‡å®šæ–‡ä»¶ï¼‰
            if input_file:
                self.logger.info(f"\n[1/4] ä½¿ç”¨æŒ‡å®šæ–‡ä»¶: {input_file}")
                raw_file = input_file
            else:
                self.logger.info("\n[1/4] æŠ“å–æ¨æ–‡...")
                raw_file = self.fetcher.run()
                if not raw_file:
                    self.logger.info("âœ“ æ— æ–°æ¨æ–‡ï¼Œæµç¨‹ç»“æŸ")
                    return None
            self.logger.info(f"âœ“ æ•°æ®æ–‡ä»¶: {raw_file}")

            # 2. å†…å®¹åˆ†æï¼ˆåˆå¹¶äº†Filter+Evaluatorï¼‰
            self.logger.info("\n[2/4] åˆ†æå†…å®¹ï¼ˆAIç›¸å…³æ€§ + ä»·å€¼è¯„ä¼°ï¼‰...")
            analyzed_file = self.analyzer.run(raw_file)
            if not analyzed_file:
                self.logger.info("âœ“ æ— é«˜ä»·å€¼AIå†…å®¹ï¼Œæµç¨‹ç»“æŸ")
                return None
            self.logger.info(f"âœ“ åˆ†æå®Œæˆ: {analyzed_file}")

            # 3. åˆ†ç±»
            self.logger.info("\n[3/4] å†…å®¹åˆ†ç±»...")
            classified_file = self.classifier.run(analyzed_file)
            if not classified_file:
                self.logger.info("âœ— åˆ†ç±»å¤±è´¥")
                return None
            self.logger.info(f"âœ“ åˆ†ç±»å®Œæˆ: {classified_file}")

            # 4. ç”Ÿæˆ
            self.logger.info("\n[4/4] ç”Ÿæˆ Markdown...")
            output_file = self.generator.run(classified_file)
            if not output_file:
                self.logger.info("âœ— ç”Ÿæˆå¤±è´¥")
                return None
            self.logger.info(f"âœ“ ç”Ÿæˆå®Œæˆ: {output_file}")

            # å®Œæˆ
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            self.logger.info("\n" + "="*70)
            self.logger.info(f"âœ“ ç®¡é“å®Œæˆï¼è€—æ—¶: {duration:.1f} ç§’")
            self.logger.info(f"âœ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
            self.logger.info("="*70)

            return output_file

        except Exception as e:
            self.logger.error(f"\nâœ— ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def get_author_report(self, min_tweets: int = 3) -> dict:
        """
        è·å–åšä¸»è´¨é‡æŠ¥å‘Š

        Args:
            min_tweets: æœ€å°‘æ¨æ–‡æ•°é‡æ‰çº³å…¥ç»Ÿè®¡

        Returns:
            åšä¸»è´¨é‡æŠ¥å‘Š
        """
        return self.analyzer.get_author_report(min_tweets)

    def print_author_report(self, min_tweets: int = 3):
        """æ‰“å°åšä¸»è´¨é‡æŠ¥å‘Š"""
        report = self.get_author_report(min_tweets)

        print("\n" + "="*70)
        print("ğŸ“Š åšä¸»è´¨é‡æŠ¥å‘Š")
        print("="*70)

        print(f"\nç»Ÿè®¡æ‘˜è¦:")
        print(f"  æ€»åšä¸»æ•°: {report['summary']['total_authors']}")
        print(f"  é«˜è´¨é‡åšä¸»: {report['summary']['high_quality_count']}")
        print(f"  ä½è´¨é‡åšä¸»: {report['summary']['low_quality_count']}")
        print(f"  å»ºè®®ç§»é™¤: {report['summary']['recommend_remove_count']}")

        if report['high_quality_authors']:
            print(f"\nâœ… é«˜è´¨é‡åšä¸» (é€šè¿‡ç‡â‰¥70%):")
            for author in report['high_quality_authors'][:10]:
                print(f"  @{author['username']:20} é€šè¿‡ç‡:{author['pass_rate']:.0%} "
                      f"å¹³å‡åˆ†:{author['avg_score']:.1f} ({author['total_tweets']}æ¡)")

        if report['recommend_remove']:
            print(f"\nâš ï¸ å»ºè®®ç§»é™¤çš„åšä¸» (é€šè¿‡ç‡â‰¤30% ä¸”è¿‘æœŸè¯„åˆ†ä½):")
            for author in report['recommend_remove']:
                print(f"  @{author['username']:20} é€šè¿‡ç‡:{author['pass_rate']:.0%} "
                      f"è¿‘æœŸå¹³å‡:{author['recent_avg_score']:.1f} ({author['total_tweets']}æ¡)")

        print("\n" + "="*70)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='AI Tweet Pipeline v2')
    parser.add_argument('--run', action='store_true', help='è¿è¡Œå®Œæ•´ç®¡é“')
    parser.add_argument('--input', type=str, help='ä½¿ç”¨æŒ‡å®šçš„åŸå§‹æ•°æ®æ–‡ä»¶')
    parser.add_argument('--author-report', action='store_true', help='ç”Ÿæˆåšä¸»è´¨é‡æŠ¥å‘Š')
    parser.add_argument('--min-tweets', type=int, default=3, help='åšä¸»æŠ¥å‘Šçš„æœ€å°æ¨æ–‡æ•°')

    args = parser.parse_args()

    pipeline = Pipeline()

    if args.author_report:
        pipeline.print_author_report(args.min_tweets)
    elif args.run or args.input:
        result = pipeline.run(input_file=args.input)
        if result:
            print(f"\nâœ“ æˆåŠŸç”ŸæˆæŠ¥å‘Š: {result}")
        else:
            print("\nâœ— æœ¬æ¬¡è¿è¡Œæœªç”ŸæˆæŠ¥å‘Š")
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
