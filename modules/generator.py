"""
ç”Ÿæˆæ¨¡å— - ç”Ÿæˆ Markdown æ–‡ä»¶
"""

from typing import Dict, Any, List
from datetime import datetime
from collections import defaultdict

from .base import BaseModule


class Generator(BaseModule):
    """Markdown ç”Ÿæˆæ¨¡å—"""

    def __init__(self, config_path: str = "config/generator.yaml"):
        super().__init__(config_path)
        self.include_metadata = self.config.get('include_metadata', True)
        self.include_links = self.config.get('include_links', True)

    def _group_by_category(self, tweets: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰åˆ†ç±»åˆ†ç»„"""
        grouped = defaultdict(list)
        for tweet in tweets:
            category = tweet['classification']['category']
            grouped[category].append(tweet)
        return dict(grouped)

    def _get_category_emoji(self, category: str) -> str:
        """è·å–åˆ†ç±» emoji"""
        emoji_map = {
            'æ—¶é—»': 'ğŸ”¥',
            'æ·±åº¦è§£æ': 'ğŸ’¡',
            'æŠ€æœ¯æŠ€å·§': 'ğŸ› ',
            'å­¦æœ¯ç ”ç©¶': 'ğŸ“š',
            'äº§å“åº”ç”¨': 'ğŸ¯',
            'å•†ä¸šæ´å¯Ÿ': 'ğŸ’¼',
        }
        return emoji_map.get(category, 'ğŸ“Œ')

    def _generate_tweet_section(self, tweet: Dict[str, Any], index: int) -> str:
        """ç”Ÿæˆå•æ¡æ¨æ–‡çš„ Markdown ç‰‡æ®µ"""
        cls = tweet['classification']
        value = tweet['value']
        user = tweet['user']

        lines = [
            f"### {index}. {cls['summary']}\n",
            f"- **æ¥æº**: [@{user['username']}]({tweet['url']}) ({user['displayname']})",
            f"- **æ—¶é—´**: {tweet['date'][:19].replace('T', ' ')}",
            f"- **ä»·å€¼è¯„åˆ†**: {value['score']}/10",
        ]

        if self.include_links:
            lines.append(f"- **åŸæ–‡**: {tweet['url']}")

        if cls.get('key_points'):
            lines.append("\n**è¦ç‚¹**:")
            for point in cls['key_points']:
                lines.append(f"  - {point}")

        # åŸæ–‡å†…å®¹ï¼ˆæŠ˜å ï¼‰
        lines.append("\n<details>")
        lines.append("<summary>æŸ¥çœ‹åŸæ–‡</summary>\n")
        lines.append(f"{tweet['content']}\n")
        lines.append("</details>\n")

        return "\n".join(lines)

    def _generate_markdown(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ Markdown"""
        tweets = data['tweets']
        fetch_time = data.get('fetch_time', datetime.now().isoformat())

        # å…ƒæ•°æ®
        lines = []
        if self.include_metadata:
            lines.extend([
                "---",
                f"generated_at: {datetime.now().isoformat()}",
                f"source_list: MY AI LIST",
                f"tweet_count: {len(tweets)}",
                f"period: {fetch_time[:13]}:00 - {fetch_time[:13]}:59",
                "---\n",
            ])

        # æ ‡é¢˜
        period_str = fetch_time[:13].replace('T', ' ')
        lines.append(f"# AI èµ„è®¯æ‘˜è¦ ({period_str}:00)\n")

        # ç»Ÿè®¡ä¿¡æ¯
        if data.get('category_stats'):
            lines.append("## ğŸ“Š æœ¬æœŸç»Ÿè®¡\n")
            for cat, count in data['category_stats'].items():
                emoji = self._get_category_emoji(cat)
                lines.append(f"- {emoji} {cat}: {count} æ¡")
            lines.append("")

        # æŒ‰åˆ†ç±»ç»„ç»‡å†…å®¹
        grouped = self._group_by_category(tweets)

        for category in ['æ—¶é—»', 'æ·±åº¦è§£æ', 'æŠ€æœ¯æŠ€å·§', 'å­¦æœ¯ç ”ç©¶', 'äº§å“åº”ç”¨', 'å•†ä¸šæ´å¯Ÿ']:
            if category not in grouped:
                continue

            cat_tweets = grouped[category]
            emoji = self._get_category_emoji(category)

            lines.append(f"\n## {emoji} {category} ({len(cat_tweets)}æ¡)\n")

            # æŒ‰ä»·å€¼åˆ†æ•°æ’åº
            sorted_tweets = sorted(
                cat_tweets,
                key=lambda t: t['value']['score'],
                reverse=True
            )

            for i, tweet in enumerate(sorted_tweets, 1):
                lines.append(self._generate_tweet_section(tweet, i))

        # é¡µè„š
        lines.extend([
            "\n---",
            "\nğŸ¤– æœ¬æ–‡ç”± AI æ¨æ–‡æŠ“å–ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ",
            f"\nğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        ])

        return "\n".join(lines)

    def run(self, input_file: str) -> str:
        """
        è¿è¡Œç”Ÿæˆ

        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ (data/classified/xxx.json)

        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½è¾“å…¥æ•°æ®
        data = self.load_json(input_file)
        if not data or 'tweets' not in data:
            self.logger.error("æ— æ•ˆçš„è¾“å…¥æ–‡ä»¶")
            return None

        self.logger.info(f"å¼€å§‹ç”Ÿæˆ Markdownï¼Œå…± {len(data['tweets'])} æ¡æ¨æ–‡")

        # ç”Ÿæˆ Markdown
        markdown = self._generate_markdown(data)

        # ä¿å­˜æ–‡ä»¶
        output_file = input_file.replace('/classified/', '/output/').replace('.json', '.md')

        from pathlib import Path
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown)

        self.logger.info(f"Markdown å·²ç”Ÿæˆ: {output_file}")
        return output_file
